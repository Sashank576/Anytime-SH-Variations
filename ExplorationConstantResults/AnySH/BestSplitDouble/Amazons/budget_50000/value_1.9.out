Warming up...
Finished warming up!
=====================================================
Completed 1 games.

Agent 1 (DoubleIterRegressionTreeSHUCTAny)
Winning score (between 0 and 1) : N=1, mean=0 (+/-0).
P1: N=1, mean=0 (+/-0).
P2: N=0, mean=0 (+/-0).
Game Durations: N=1, mean=132 (+/-0).
P1: N=1, mean=132 (+/-0).
P2: N=0, mean=0 (+/-0).

Agent 2 (SHUCTAnyTime)
Winning score (between 0 and 1) : N=1, mean=1 (+/-0).
P1: N=0, mean=0 (+/-0).
P2: N=1, mean=1 (+/-0).
Game Durations: N=1, mean=132 (+/-0).
P1: N=0, mean=0 (+/-0).
P2: N=1, mean=132 (+/-0).
=====================================================
=====================================================
Completed 2 games.

Agent 1 (DoubleIterRegressionTreeSHUCTAny)
Winning score (between 0 and 1) : N=2, mean=0.5 (+/-0.97998).
P1: N=1, mean=0 (+/-0).
P2: N=1, mean=1 (+/-0).
Game Durations: N=2, mean=148 (+/-31.35936).
P1: N=1, mean=132 (+/-0).
P2: N=1, mean=164 (+/-0).

Agent 2 (SHUCTAnyTime)
Winning score (between 0 and 1) : N=2, mean=0.5 (+/-0.97998).
P1: N=1, mean=0 (+/-0).
P2: N=1, mean=1 (+/-0).
Game Durations: N=2, mean=148 (+/-31.35936).
P1: N=1, mean=164 (+/-0).
P2: N=1, mean=132 (+/-0).
=====================================================
=====================================================
Completed 3 games.

Agent 1 (DoubleIterRegressionTreeSHUCTAny)
Winning score (between 0 and 1) : N=3, mean=0.666667 (+/-0.65332).
P1: N=2, mean=0.5 (+/-0.97998).
P2: N=1, mean=1 (+/-0).
Game Durations: N=3, mean=152.666667 (+/-20.284508).
P1: N=2, mean=147 (+/-29.3994).
P2: N=1, mean=164 (+/-0).

Agent 2 (SHUCTAnyTime)
Winning score (between 0 and 1) : N=3, mean=0.333333 (+/-0.65332).
P1: N=1, mean=0 (+/-0).
P2: N=2, mean=0.5 (+/-0.97998).
Game Durations: N=3, mean=152.666667 (+/-20.284508).
P1: N=1, mean=164 (+/-0).
P2: N=2, mean=147 (+/-29.3994).
=====================================================
=====================================================
Completed 4 games.

Agent 1 (DoubleIterRegressionTreeSHUCTAny)
Winning score (between 0 and 1) : N=4, mean=0.5 (+/-0.565792).
P1: N=2, mean=0.5 (+/-0.97998).
P2: N=2, mean=0.5 (+/-0.97998).
Game Durations: N=4, mean=155 (+/-15.054738).
P1: N=2, mean=147 (+/-29.3994).
P2: N=2, mean=163 (+/-1.95996).

Agent 2 (SHUCTAnyTime)
Winning score (between 0 and 1) : N=4, mean=0.5 (+/-0.565792).
P1: N=2, mean=0.5 (+/-0.97998).
P2: N=2, mean=0.5 (+/-0.97998).
Game Durations: N=4, mean=155 (+/-15.054738).
P1: N=2, mean=163 (+/-1.95996).
P2: N=2, mean=147 (+/-29.3994).
=====================================================
=====================================================
Completed 5 games.

Agent 1 (DoubleIterRegressionTreeSHUCTAny)
Winning score (between 0 and 1) : N=5, mean=0.4 (+/-0.48009).
P1: N=3, mean=0.333333 (+/-0.65332).
P2: N=2, mean=0.5 (+/-0.97998).
Game Durations: N=5, mean=157.6 (+/-12.726164).
P1: N=3, mean=154 (+/-21.825191).
P2: N=2, mean=163 (+/-1.95996).

Agent 2 (SHUCTAnyTime)
Winning score (between 0 and 1) : N=5, mean=0.6 (+/-0.48009).
P1: N=2, mean=0.5 (+/-0.97998).
P2: N=3, mean=0.666667 (+/-0.65332).
Game Durations: N=5, mean=157.6 (+/-12.726164).
P1: N=2, mean=163 (+/-1.95996).
P2: N=3, mean=154 (+/-21.825191).
=====================================================
=====================================================
Completed 10 games.

Agent 1 (DoubleIterRegressionTreeSHUCTAny)
Winning score (between 0 and 1) : N=10, mean=0.3 (+/-0.299389).
P1: N=5, mean=0.2 (+/-0.391992).
P2: N=5, mean=0.4 (+/-0.48009).
Game Durations: N=10, mean=154.4 (+/-9.254111).
P1: N=5, mean=148.4 (+/-15.601085).
P2: N=5, mean=160.4 (+/-8.53427).

Agent 2 (SHUCTAnyTime)
Winning score (between 0 and 1) : N=10, mean=0.7 (+/-0.299389).
P1: N=5, mean=0.6 (+/-0.48009).
P2: N=5, mean=0.8 (+/-0.391992).
Game Durations: N=10, mean=154.4 (+/-9.254111).
P1: N=5, mean=160.4 (+/-8.53427).
P2: N=5, mean=148.4 (+/-15.601085).
=====================================================
=====================================================
Completed 20 games.

Agent 1 (DoubleIterRegressionTreeSHUCTAny)
Winning score (between 0 and 1) : N=20, mean=0.4 (+/-0.22028).
P1: N=10, mean=0.3 (+/-0.299389).
P2: N=10, mean=0.5 (+/-0.32666).
Game Durations: N=20, mean=154.8 (+/-7.241389).
P1: N=10, mean=149.4 (+/-12.628525).
P2: N=10, mean=160.2 (+/-6.085352).

Agent 2 (SHUCTAnyTime)
Winning score (between 0 and 1) : N=20, mean=0.6 (+/-0.22028).
P1: N=10, mean=0.5 (+/-0.32666).
P2: N=10, mean=0.7 (+/-0.299389).
Game Durations: N=20, mean=154.8 (+/-7.241389).
P1: N=10, mean=160.2 (+/-6.085352).
P2: N=10, mean=149.4 (+/-12.628525).
=====================================================
=====================================================
Completed 30 games.

Agent 1 (DoubleIterRegressionTreeSHUCTAny)
Winning score (between 0 and 1) : N=30, mean=0.5 (+/-0.181978).
P1: N=15, mean=0.466667 (+/-0.261328).
P2: N=15, mean=0.533333 (+/-0.261328).
Game Durations: N=30, mean=155.6 (+/-5.836617).
P1: N=15, mean=151.6 (+/-9.379767).
P2: N=15, mean=159.6 (+/-6.661118).

Agent 2 (SHUCTAnyTime)
Winning score (between 0 and 1) : N=30, mean=0.5 (+/-0.181978).
P1: N=15, mean=0.466667 (+/-0.261328).
P2: N=15, mean=0.533333 (+/-0.261328).
Game Durations: N=30, mean=155.6 (+/-5.836617).
P1: N=15, mean=159.6 (+/-6.661118).
P2: N=15, mean=151.6 (+/-9.379767).
=====================================================
=====================================================
Completed 40 games.

Agent 1 (DoubleIterRegressionTreeSHUCTAny)
Winning score (between 0 and 1) : N=40, mean=0.425 (+/-0.155147).
P1: N=20, mean=0.4 (+/-0.22028).
P2: N=20, mean=0.45 (+/-0.223696).
Game Durations: N=40, mean=156.95 (+/-5.058624).
P1: N=20, mean=154.8 (+/-8.293007).
P2: N=20, mean=159.1 (+/-5.865937).

Agent 2 (SHUCTAnyTime)
Winning score (between 0 and 1) : N=40, mean=0.575 (+/-0.155147).
P1: N=20, mean=0.55 (+/-0.223696).
P2: N=20, mean=0.6 (+/-0.22028).
Game Durations: N=40, mean=156.95 (+/-5.058624).
P1: N=20, mean=159.1 (+/-5.865937).
P2: N=20, mean=154.8 (+/-8.293007).
=====================================================
=====================================================
Completed 50 games.

Agent 1 (DoubleIterRegressionTreeSHUCTAny)
Winning score (between 0 and 1) : N=50, mean=0.36 (+/-0.134397).
P1: N=25, mean=0.36 (+/-0.192036).
P2: N=25, mean=0.36 (+/-0.192036).
Game Durations: N=50, mean=157.64 (+/-4.592849).
P1: N=25, mean=156.56 (+/-6.929579).
P2: N=25, mean=158.72 (+/-6.143487).

Agent 2 (SHUCTAnyTime)
Winning score (between 0 and 1) : N=50, mean=0.64 (+/-0.134397).
P1: N=25, mean=0.64 (+/-0.192036).
P2: N=25, mean=0.64 (+/-0.192036).
Game Durations: N=50, mean=157.64 (+/-4.592849).
P1: N=25, mean=158.72 (+/-6.143487).
P2: N=25, mean=156.56 (+/-6.929579).
=====================================================
=====================================================
Completed 60 games.

Agent 1 (DoubleIterRegressionTreeSHUCTAny)
Winning score (between 0 and 1) : N=60, mean=0.366667 (+/-0.122963).
P1: N=30, mean=0.366667 (+/-0.175388).
P2: N=30, mean=0.366667 (+/-0.175388).
Game Durations: N=60, mean=157.266667 (+/-4.24011).
P1: N=30, mean=157.133333 (+/-6.274922).
P2: N=30, mean=157.4 (+/-5.811598).

Agent 2 (SHUCTAnyTime)
Winning score (between 0 and 1) : N=60, mean=0.633333 (+/-0.122963).
P1: N=30, mean=0.633333 (+/-0.175388).
P2: N=30, mean=0.633333 (+/-0.175388).
Game Durations: N=60, mean=157.266667 (+/-4.24011).
P1: N=30, mean=157.4 (+/-5.811598).
P2: N=30, mean=157.133333 (+/-6.274922).
=====================================================
=====================================================
Completed 70 games.

Agent 1 (DoubleIterRegressionTreeSHUCTAny)
Winning score (between 0 and 1) : N=70, mean=0.4 (+/-0.115592).
P1: N=35, mean=0.4 (+/-0.16467).
P2: N=35, mean=0.4 (+/-0.16467).
Game Durations: N=70, mean=157.114286 (+/-3.844228).
P1: N=35, mean=157.485714 (+/-5.797151).
P2: N=35, mean=156.742857 (+/-5.132596).

Agent 2 (SHUCTAnyTime)
Winning score (between 0 and 1) : N=70, mean=0.6 (+/-0.115592).
P1: N=35, mean=0.6 (+/-0.16467).
P2: N=35, mean=0.6 (+/-0.16467).
Game Durations: N=70, mean=157.114286 (+/-3.844228).
P1: N=35, mean=156.742857 (+/-5.132596).
P2: N=35, mean=157.485714 (+/-5.797151).
=====================================================
=====================================================
Completed 80 games.

Agent 1 (DoubleIterRegressionTreeSHUCTAny)
Winning score (between 0 and 1) : N=80, mean=0.4 (+/-0.108029).
P1: N=40, mean=0.425 (+/-0.155147).
P2: N=40, mean=0.375 (+/-0.151939).
Game Durations: N=80, mean=156.55 (+/-3.547429).
P1: N=40, mean=157.65 (+/-5.200527).
P2: N=40, mean=155.45 (+/-4.868111).

Agent 2 (SHUCTAnyTime)
Winning score (between 0 and 1) : N=80, mean=0.6 (+/-0.108029).
P1: N=40, mean=0.625 (+/-0.151939).
P2: N=40, mean=0.575 (+/-0.155147).
Game Durations: N=80, mean=156.55 (+/-3.547429).
P1: N=40, mean=155.45 (+/-4.868111).
P2: N=40, mean=157.65 (+/-5.200527).
=====================================================
=====================================================
Completed 90 games.

Agent 1 (DoubleIterRegressionTreeSHUCTAny)
Winning score (between 0 and 1) : N=90, mean=0.411111 (+/-0.102223).
P1: N=45, mean=0.422222 (+/-0.145939).
P2: N=45, mean=0.4 (+/-0.144753).
Game Durations: N=90, mean=156.666667 (+/-3.352816).
P1: N=45, mean=156.933333 (+/-4.996704).
P2: N=45, mean=156.4 (+/-4.527362).

Agent 2 (SHUCTAnyTime)
Winning score (between 0 and 1) : N=90, mean=0.588889 (+/-0.102223).
P1: N=45, mean=0.6 (+/-0.144753).
P2: N=45, mean=0.577778 (+/-0.145939).
Game Durations: N=90, mean=156.666667 (+/-3.352816).
P1: N=45, mean=156.4 (+/-4.527362).
P2: N=45, mean=156.933333 (+/-4.996704).
=====================================================
=====================================================
Completed 100 games.

Agent 1 (DoubleIterRegressionTreeSHUCTAny)
Winning score (between 0 and 1) : N=100, mean=0.42 (+/-0.097223).
P1: N=50, mean=0.46 (+/-0.139548).
P2: N=50, mean=0.38 (+/-0.135905).
Game Durations: N=100, mean=156.28 (+/-3.180178).
P1: N=50, mean=157.4 (+/-4.651951).
P2: N=50, mean=155.16 (+/-4.362293).

Agent 2 (SHUCTAnyTime)
Winning score (between 0 and 1) : N=100, mean=0.58 (+/-0.097223).
P1: N=50, mean=0.62 (+/-0.135905).
P2: N=50, mean=0.54 (+/-0.139548).
Game Durations: N=100, mean=156.28 (+/-3.180178).
P1: N=50, mean=155.16 (+/-4.362293).
P2: N=50, mean=157.4 (+/-4.651951).
=====================================================
